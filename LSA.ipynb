{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d11a7d83",
   "metadata": {},
   "source": [
    "## Bertopic\n",
    "- For semantic text understanding\n",
    "- Uses a different modeling library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea1c005",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c94a3948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title          Query\n",
      "0                         South America  Google News  South America\n",
      "1  South American trade bloc Mercosur holds summi...  South America\n",
      "2  Minnesota National Guard Deploying to South Am...  South America\n",
      "3  Extreme weather in Latin America unlocks vicio...  South America\n",
      "4  Volkswagen aims to grow 40 in S America throug...  South America\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('titles_data.csv')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3500ff2d",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac6d431c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tyler\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tyler\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def preprocess_title(title):\n",
    "    title = title.lower()\n",
    "    tokens = word_tokenize(title)\n",
    "    tokens = [token for token in tokens if token not in stop_words and token not in string.punctuation]\n",
    "    preprocessed_title = ' '.join(tokens)\n",
    "\n",
    "    return preprocessed_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "349493a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                               south america google news\n",
      "1       south american trade bloc mercosur holds summi...\n",
      "2       minnesota national guard deploying south ameri...\n",
      "3       extreme weather latin america unlocks vicious ...\n",
      "4       volkswagen aims grow 40 america ev subscriptio...\n",
      "                              ...                        \n",
      "1214    us trying mend ties venezuela one big reason o...\n",
      "1215    decade maduro migration marks venezuelans live...\n",
      "1216    venezuelas juan guaid√≥ seeks support washingto...\n",
      "1217    joint statement venezuela negotiations united ...\n",
      "1218    opinion venezuelas crisis must resolved peacef...\n",
      "Name: Preprocessed Title, Length: 1219, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['Preprocessed Title'] = df['Title'].apply(preprocess_title)\n",
    "print(df['Preprocessed Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dc2d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['Preprocessed Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1ee80fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: news, google, america, south, argentina\n",
      "Topic 2: google, news, guyanaparaguay, stabroek, loop\n",
      "Topic 3: america, south, latin, market, caribbean\n",
      "Topic 4: prensa, latina, la, venezuela, uruguay\n",
      "Topic 5: english, bnamericas, brazil, new, suriname\n",
      "Topic 6: reuters, brazil, latina, prensa, canada\n",
      "Topic 7: brazil, espn, world, uruguay, argentina\n",
      "Topic 8: 2023, reliefweb, ecuador, peru, argentina\n",
      "Topic 9: suriname, argentina, international, imf, monetary\n",
      "Topic 10: venezuela, united, states, latin, state\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "num_topics = 10\n",
    "lsa_model = TruncatedSVD(n_components=num_topics)\n",
    "lsa_matrix = lsa_model.fit_transform(tfidf_matrix)\n",
    "\n",
    "# Extract keywords from LSA components\n",
    "terms = vectorizer.get_feature_names()\n",
    "for topic_idx, topic in enumerate(lsa_model.components_):\n",
    "    top_keywords = [terms[i] for i in topic.argsort()[:-5 - 1:-1]] \n",
    "    print(f\"Topic {topic_idx + 1}: {', '.join(top_keywords)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
